{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1AeGAmTTCgw"
   },
   "outputs": [],
   "source": [
    "! pip install transformers[sentencepiece] datasets tokenizers evaluate\n",
    "! pip install torch\n",
    "! pip install tensorflow\n",
    "! pip install spacy\n",
    "! pip install seqeval\n",
    "! pip install ipywidgets\n",
    "! pip install \"ray[tune]\" scipy sklearn\n",
    "! pip install pyinterval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23247,
     "status": "ok",
     "timestamp": 1676902400591,
     "user": {
      "displayName": "Tianjian Huang",
      "userId": "09867676290989603145"
     },
     "user_tz": 300
    },
    "id": "P4lDdgUiTLkr",
    "outputId": "74dad616-d098-4f62-c443-b687d90c9645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive/mobile_privacy/cleaned/models\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/mobile_privacy/cleaned/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1676902955908,
     "user": {
      "displayName": "Tianjian Huang",
      "userId": "09867676290989603145"
     },
     "user_tz": 300
    },
    "id": "DHgc0vDJMU4r"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from interval import interval\n",
    "from copy import deepcopy\n",
    "from random import shuffle\n",
    "from functools import cmp_to_key\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from spacy.training import offsets_to_biluo_tags, biluo_to_iob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1676902957887,
     "user": {
      "displayName": "Tianjian Huang",
      "userId": "09867676290989603145"
     },
     "user_tz": 300
    },
    "id": "rynhbfrHSsGi"
   },
   "outputs": [],
   "source": [
    "def replace_linebreak(text):\n",
    "  return text.replace(\"\\r\",\"\")\n",
    "\n",
    "def load_jsonl_file(filename):\n",
    "  '''\n",
    "  load the original jsonl file.\n",
    "  replace the line break \\r\\n to \\n, in order to get correct label offset.\n",
    "  return a list of dict{'text':string, 'label':list of [start, end, category]}\n",
    "  '''\n",
    "  jsonl_content = open(filename,'r').read()\n",
    "  result = [json.loads(jline) for jline in jsonl_content.splitlines()]\n",
    "  for data in result:\n",
    "    data['text'] = replace_linebreak(data['text'])\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1676906557210,
     "user": {
      "displayName": "Tianjian Huang",
      "userId": "09867676290989603145"
     },
     "user_tz": 300
    },
    "id": "-St-XHu4SzIE"
   },
   "outputs": [],
   "source": [
    "def overlapped(label1, label2):\n",
    "  ''' \n",
    "  Input: two labels with [start, end, category]\n",
    "  Output: whether they are overlapped\n",
    "  Notice that the range of token is [start, end), end is exclusive\n",
    "  '''\n",
    "  start1, end1 = label1[0], label1[1]-1\n",
    "  start2, end2 = label2[0], label2[1]-1\n",
    "  r1 = interval([start1, end1])\n",
    "  r2 = interval([start2, end2])\n",
    "  if len((r1 & r2)) == 0:\n",
    "    return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1676906561358,
     "user": {
      "displayName": "Tianjian Huang",
      "userId": "09867676290989603145"
     },
     "user_tz": 300
    },
    "id": "C_M7k6ump4of"
   },
   "outputs": [],
   "source": [
    "url_df = pd.read_csv('./app_name_category_300.csv', encoding='latin',on_bad_lines = 'warn')\n",
    "id_app = {}\n",
    "for index, row in url_df.iterrows():\n",
    "  id_app[row['scenario_id']] = [row['app_name'], row['app_category'], row['scenario_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1676906561636,
     "user": {
      "displayName": "Tianjian Huang",
      "userId": "09867676290989603145"
     },
     "user_tz": 300
    },
    "id": "21T3GVZ1AfSW"
   },
   "outputs": [],
   "source": [
    "jsonl_file = load_jsonl_file('./raw_300_scenarios.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16274,
     "status": "ok",
     "timestamp": 1676906579539,
     "user": {
      "displayName": "Tianjian Huang",
      "userId": "09867676290989603145"
     },
     "user_tz": 300
    },
    "id": "xtCp0TPEyoex",
    "outputId": "606f3f61-fe28-49e6-965a-02b0bf876d8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The goals that I want to achieve through this scre...\" with entities \"[[94, 123, 'Questions'], [805, 846, 'Questions'], ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"When I open up the Twitch app and navigate to the ...\" with entities \"[[590, 630, 'Complex Terms'], [898, 964, 'Complex ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I use this screen in the applicate google translat...\" with entities \"[[334, 354, 'Complex Terms'], [613, 636, 'Complex ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"This screen is used by me because it shows exactly...\" with entities \"[[51, 93, 'Questions'], [135, 146, 'Questions'], [...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"This is the overview page of an investment account...\" with entities \"[[342, 389, 'Complex Terms'], [667, 701, 'Complex ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I log into the app on a daily basis and the first ...\" with entities \"[[105, 124, 'Noun Phrase'], [160, 167, 'Noun Phras...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I use this screen as part of the video recording a...\" with entities \"[[33, 38, 'Noun Phrase'], [243, 249, 'Noun Phrase'...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I scan potential products I may want to buy in the...\" with entities \"[[70, 86, 'Questions'], [192, 209, 'Questions'], [...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I use the app to find the best route, to plan a tr...\" with entities \"[[59, 94, 'Complex Terms'], [327, 345, 'Questions'...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"This screen brings up daily health surveys that I ...\" with entities \"[[200, 229, 'Questions'], [234, 291, 'Questions'],...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from re import I\n",
    "\n",
    "label_match_dict = {\n",
    "    'O':'O',\n",
    "    'B-Noun Phrase':'B-SIM',\n",
    "    'I-Noun Phrase': 'I-SIM',\n",
    "    'B-Complex Terms':'B-COM',\n",
    "    'I-Complex Terms':'I-COM',\n",
    "    'B-Questions':'B-QUE',\n",
    "    'I-Questions':'I-QUE'\n",
    "}\n",
    "\n",
    "def find_overlap(label1, label_list):\n",
    "  for i in range(len(label_list)):\n",
    "    if overlapped(label1, label_list[i]):\n",
    "      return i\n",
    "  return -1\n",
    "\n",
    "def dedup_scenario_label(jsonl_list):\n",
    "  '''\n",
    "  Deduplication rules:\n",
    "  If noun phrase conflict with clause, keep clause only.\n",
    "  If clause conflict with each other, keep the longest one.\n",
    "  If noun conflict with each other, keep the shortest one.\n",
    "  '''\n",
    "  res = []\n",
    "  for scenario in jsonl_list:\n",
    "    tmp = {}\n",
    "    tmp['id'] = scenario['id']\n",
    "    tmp['text'] = scenario['text']\n",
    "    tmp['app_url'] = scenario['app_url']\n",
    "    tmp['scenario_id'] = scenario['scenario_id']\n",
    "    tmp['raw_label'] = deepcopy(scenario['label'])\n",
    "    tmp['app_name'] = id_app[scenario['scenario_id']][0]\n",
    "    tmp['app_category'] = id_app[scenario['scenario_id']][1]\n",
    "    labels = list()\n",
    "    noun = list()\n",
    "    clause = list()\n",
    "    for label in scenario['label']:\n",
    "      start, end, category = label\n",
    "      if category == 'Noun Phrase':\n",
    "        noun.append(label)\n",
    "      else:\n",
    "        clause.append(label)\n",
    "    # add non-conflict clause first\n",
    "    for label in clause:\n",
    "      ind = find_overlap(label, labels)\n",
    "      if ind == -1:\n",
    "        labels.append(label)\n",
    "      else:\n",
    "        if labels[ind][1] - labels[ind][0] < label[1] - label[0]:\n",
    "          labels[ind] = label\n",
    "    # dedup noun\n",
    "    dedup_noun = list()\n",
    "    for label in noun:\n",
    "      ind = find_overlap(label, dedup_noun)\n",
    "      if ind == -1:\n",
    "        dedup_noun.append(label)\n",
    "      else:\n",
    "        if dedup_noun[ind][1] - dedup_noun[ind][0] > label[1] - label[0]:\n",
    "          dedup_noun[ind] = label\n",
    "    # add non-conflict noun\n",
    "    for label in dedup_noun:\n",
    "      ind = find_overlap(label, labels)\n",
    "      if ind == -1:\n",
    "        labels.append(label)\n",
    "    tmp['label'] = labels\n",
    "    res.append(tmp)\n",
    "  return res\n",
    "\n",
    "\n",
    "def convert_jsonl_to_bio(jsonl_list):\n",
    "  res = {}\n",
    "  for data in jsonl_list:\n",
    "    id = data['scenario_id']\n",
    "    clean_text = data['text']\n",
    "    raw_labels = deepcopy(data['label'])\n",
    "    labels = data['label']\n",
    "    doc = nlp(clean_text)\n",
    "    biluo_tags = offsets_to_biluo_tags(doc, labels)\n",
    "    iob_tags = biluo_to_iob(biluo_tags)\n",
    "    codes = list()\n",
    "    for c in iob_tags:\n",
    "        codes.append(label_match_dict.get(c,'O'))\n",
    "    res[id] = {'id':id,\n",
    "               'text':clean_text,\n",
    "               'words': [str(token) for token in doc],\n",
    "               'codes':codes,\n",
    "               'raw_labels': raw_labels,\n",
    "               'app_name':data['app_name'],\n",
    "               'app_category':data['app_category']}\n",
    "  return res\n",
    "\n",
    "dedup_jsonl_file = dedup_scenario_label(jsonl_file)\n",
    "bio_jsonl = convert_jsonl_to_bio(dedup_jsonl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1676906579540,
     "user": {
      "displayName": "Tianjian Huang",
      "userId": "09867676290989603145"
     },
     "user_tz": 300
    },
    "id": "7aMmZz90TSTd"
   },
   "outputs": [],
   "source": [
    "with open('./scenarios-labeled.json', 'w') as f:\n",
    "  f.write(json.dumps(bio_jsonl))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMeluQ3fR1iUgcFvSNgjQ95",
   "provenance": [
    {
     "file_id": "1S3EEP-SJqBzNwLroFejNOC7RTNt6um32",
     "timestamp": 1676902184043
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
