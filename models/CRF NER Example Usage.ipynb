{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#let-s-use-conll-2002-data-to-build-a-ner-system\n",
    "# functions to create NER features\n",
    "\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('crf.model', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, nltk, json\n",
    "\n",
    "# load the spacey nlp processor\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def segment_text(scenario_text):    \n",
    "    # parse scenario text to tokenize sentences\n",
    "    doc = nlp(scenario_text)\n",
    "    tag = [t for w, t in nltk.pos_tag([t.text for t in doc], tagset='universal')]\n",
    "    \n",
    "    sentences = []\n",
    "    sent = []\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.is_sent_start and len(sent) > 0:\n",
    "            sentences.append(sent)\n",
    "            sent = []\n",
    "        sent.append([token.text, tag[i], token.idx])\n",
    "    sentences.append(sent)\n",
    "    return sentences\n",
    "\n",
    "# load the scenario data\n",
    "dataset = json.load(open('../datasets/scenarios-labeled.json', 'r'))\n",
    "scenarios = list(dataset.values())\n",
    "\n",
    "segments = segment_text(scenarios[0]['text'])\n",
    "X = [sent2features(s) for s in segments]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From           \tO\n",
      "this           \tO\n",
      "screen         \tO\n",
      ",              \tO\n",
      "I              \tO\n",
      "like           \tO\n",
      "to             \tO\n",
      "search         \tO\n",
      "for            \tO\n",
      "anything       \tO\n",
      "from           \tO\n",
      "recipes        \tB-SIM\n",
      ",              \tO\n",
      "to             \tO\n",
      "home           \tB-SIM\n",
      "decor          \tI-SIM\n",
      ",              \tO\n",
      "to             \tO\n",
      "people         \tB-SIM\n",
      ",              \tO\n",
      "etc            \tO\n",
      ".              \tO\n",
      ",              \tO\n",
      "just           \tO\n",
      "depending      \tO\n",
      "on             \tO\n",
      "my             \tO\n",
      "mood           \tO\n",
      ".              \tO\n",
      "To             \tO\n",
      "get            \tO\n",
      "to             \tO\n",
      "this           \tO\n",
      "screen         \tO\n",
      "all            \tO\n",
      "I              \tO\n",
      "had            \tO\n",
      "to             \tO\n",
      "do             \tO\n",
      "was            \tO\n",
      "tap            \tO\n",
      "on             \tO\n",
      "the            \tO\n",
      "little         \tO\n",
      "magnifying     \tO\n",
      "glass          \tO\n",
      "next           \tO\n",
      "to             \tO\n",
      "the            \tO\n",
      "image          \tO\n",
      "of             \tO\n",
      "the            \tO\n",
      "home           \tO\n",
      "icon           \tO\n",
      ",              \tO\n",
      "and            \tO\n",
      "this           \tO\n",
      "is             \tO\n",
      "where          \tO\n",
      "you            \tO\n",
      "would          \tO\n",
      "search         \tO\n",
      "for            \tO\n",
      "whatever       \tO\n",
      "you            \tO\n",
      "like           \tO\n",
      ",              \tO\n",
      "kind           \tO\n",
      "of             \tO\n",
      "like           \tO\n",
      "how            \tO\n",
      "it             \tO\n",
      "works          \tO\n",
      "with           \tO\n",
      "google         \tO\n",
      ",              \tO\n",
      "but            \tO\n",
      "more           \tO\n",
      "customized     \tO\n",
      "to             \tO\n",
      "your           \tO\n",
      "preferences    \tB-SIM\n",
      "and            \tO\n",
      "trends         \tB-SIM\n",
      ".              \tO\n",
      "To             \tO\n",
      "find           \tO\n",
      "whatever       \tO\n",
      "I              \tO\n",
      "'m             \tO\n",
      "looking        \tO\n",
      "for            \tO\n",
      ",              \tO\n",
      "I              \tO\n",
      "click          \tO\n",
      "on             \tO\n",
      "the            \tO\n",
      "search         \tB-SIM\n",
      "bar            \tI-SIM\n",
      "to             \tO\n",
      "type           \tO\n",
      "a              \tO\n",
      "word           \tB-SIM\n",
      "or             \tO\n",
      "phrase         \tB-SIM\n",
      ".              \tO\n",
      "I              \tO\n",
      "try            \tO\n",
      "to             \tO\n",
      "keep           \tO\n",
      "it             \tO\n",
      "brief          \tO\n",
      ".              \tO\n",
      "For            \tO\n",
      "example        \tO\n",
      ",              \tO\n",
      "if             \tO\n",
      "I              \tO\n",
      "'m             \tO\n",
      "looking        \tO\n",
      "for            \tO\n",
      "a              \tO\n",
      "pasta          \tO\n",
      "recipe         \tB-SIM\n",
      "for            \tO\n",
      "dinner         \tO\n",
      ",              \tO\n",
      "I              \tO\n",
      "'ll            \tO\n",
      "type           \tO\n",
      "pasta          \tO\n",
      "dinner         \tO\n",
      "recipe         \tB-SIM\n",
      ",              \tO\n",
      "then           \tO\n",
      "select         \tO\n",
      "the            \tO\n",
      "phrase         \tB-SIM\n",
      "that           \tO\n",
      "matches        \tO\n",
      "what           \tO\n",
      "I              \tO\n",
      "'m             \tO\n",
      "looking        \tO\n",
      "for            \tO\n",
      ".              \tO\n",
      "I              \tO\n",
      "then           \tO\n",
      "rummage        \tO\n",
      "through        \tO\n",
      "the            \tO\n",
      "available      \tO\n",
      "pins           \tO\n",
      "and            \tO\n",
      "decide         \tO\n",
      "which          \tO\n",
      "one            \tO\n",
      "I              \tO\n",
      "like           \tO\n",
      "the            \tO\n",
      "most           \tO\n",
      "before         \tO\n",
      "saving         \tO\n",
      "the            \tO\n",
      "pin            \tO\n",
      "to             \tO\n",
      "the            \tO\n",
      "board          \tB-SIM\n",
      "that           \tO\n",
      "most           \tO\n",
      "closely        \tO\n",
      "matches        \tO\n",
      "the            \tO\n",
      "kind           \tO\n",
      "of             \tO\n",
      "query          \tO\n",
      "I              \tO\n",
      "made           \tO\n",
      ".              \tO\n"
     ]
    }
   ],
   "source": [
    "entities = []\n",
    "for i in range(len(segments)):\n",
    "    for j in range(len(segments[i])):\n",
    "        text = segments[i][j][0]\n",
    "        text_start = segments[i][j][2]\n",
    "        text_end = text_start + len(text)\n",
    "        label = y_pred[i][j]\n",
    "        print('%s\\t%s' % (text.ljust(15), label))\n",
    "        \n",
    "        if label.startswith('B-'):\n",
    "            entities.append({'start': text_start, 'end': text_end, 'entity_group': label[2:]})\n",
    "        elif label.startswith('I-'):\n",
    "            entities[-1]['end'] = text_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 entities\n",
      "recipes (SIM)\n",
      "home decor (SIM)\n",
      "people (SIM)\n",
      "preferences (SIM)\n",
      "trends (SIM)\n",
      "search bar (SIM)\n",
      "word (SIM)\n",
      "phrase (SIM)\n",
      "recipe (SIM)\n",
      "recipe (SIM)\n",
      "phrase (SIM)\n",
      "board (SIM)\n"
     ]
    }
   ],
   "source": [
    "print('Found %i entities' % len(entities))\n",
    "for entity in entities:\n",
    "    print('%s (%s)' % (scenarios[0]['text'][entity['start']:entity['end']], entity['entity_group']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
